<!DOCTYPE html>
<!-- _layouts/distill.html -->
<html>
  <head>        
    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Humberto  Gonz치lez Ram칤rez | Station'Air</title>
    <meta name="author" content="Humberto  Gonz치lez Ram칤rez" />
    <meta name="description" content="Postdoctoral project in land vehicle tracking from drone videos" />
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://gitcdn.link/repo/jwarby/jekyll-pygments-themes/master/github.css" />

    <!-- Styles -->
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>游늵</text></svg>">
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://humbertog.github.io/projects/project_stationair/">

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Distill js -->
    <script src="/assets/js/distillpub/template.v2.js"></script>
    <script src="/assets/js/distillpub/transforms.v2.js"></script>
    
  </head>

  <d-front-matter>
    <script async type="text/json">{
      "title": "Station'Air",
      "description": "Postdoctoral project in land vehicle tracking from drone videos",
      "published": "August 31, 2021",
      "authors": [
        {
          "author": "Humberto Gonz치lez R.",
          "authorURL": "",
          "affiliations": [
            {
              "name": "LICIT, Univ. Gustave Eiffel",
              "url": ""
            }
          ]
        },
        {
          "author": "Pierre Lemaire",
          "authorURL": "",
          "affiliations": [
            {
              "name": "LICIT, Univ. Gustave Eiffel",
              "url": ""
            }
          ]
        },
        {
          "author": "Nour-Eddin El Faouzi",
          "authorURL": "",
          "affiliations": [
            {
              "name": "LICIT, Univ. Gustave Eiffel",
              "url": ""
            }
          ]
        }
        
      ],
      "katex": {
        "delimiters": [
          {
            "left": "$",
            "right": "$",
            "display": false
          },
          {
            "left": "$$",
            "right": "$$",
            "display": true
          }
        ]
      }
    }</script>
  </d-front-matter>

  <body class="fixed-top-nav">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://humbertog.github.io/"><span class="font-weight-bold">Humberto</span>   Gonz치lez Ram칤rez</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              

              <!-- Other pages -->
              

              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>
              

              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">publications</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/publications_sci/">scientific articles</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/publications_rep/">opinion &amp; vulgarisation</a>
                </div>
              </li>
<!-- PDMX -->
              <li class="nav-item">
                <a class="nav-link" href="https://puntodecimal.mx/author/humberto-gora" target="_blank" rel="noopener noreferrer">blog:PuntoDecimalMX
                </a>
              </li>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="post distill">

      <d-title>
        <h1>Station'Air</h1>
        <p>Postdoctoral project in land vehicle tracking from drone videos</p>
      </d-title>

      <d-byline></d-byline>

      <d-article>
        <d-contents>
          <nav class="l-text figcaption">
          <h3>Contents</h3>
            <div><a href="#introduction">Introduction</a></div>
            <div><a href="#resuls">Resuls</a></div>
            <ul>
              <li><a href="#performance">Performance</a></li>
              
            </ul>
<div><a href="#conclusionsd">Conclusionsd</a></div>
            
          </nav>
        </d-contents>

        <p><strong>Keywords:</strong> multiple object tracking, Kalman filter, convolutional network detector, unmanned aerial vehicle (UAV), traffic monitoring</p>

<h2 id="introduction">Introduction</h2>

<h4 id="what">What</h4>
<p>A methodology for online (pseudo real-time) vehicle tracking and estimation of road traffic summaries from videos acquired by tethered (wired) unmanned aerial vehicles (UAVs). The advantage of UAVs in traffic monitoring is that they can be deployed quickly, in a variety of places and at a reasonable cost, when compared to classic fixed surveillance cameras or loop detectors.</p>

<h4 id="problem">Problem</h4>
<p>Firstly, since the camera is not fixed, videos are prone to <code class="language-plaintext highlighter-rouge">small instabilities</code> and variations of the viewpoint, caused by windy conditions and the drone navigation system. Secondly, due to the tether and for safety reasons, our drone cannot be placed directly above the road infrastructure and, thus, the <code class="language-plaintext highlighter-rouge">aerial view is oblique</code>, producing images with a large depth of field (far away objects) and occlusions. Furthermore, distances in the visual plane (pixels) need to be transformed to metric in order to be able to compute the speeds of the vehicles in the scene. Thirdly, the solution must be <code class="language-plaintext highlighter-rouge">site-agnostic</code>, meaning that we cannot embed the scene topology into most steps: the solution must be able to track vehicles and compute traffic metrics at any place, requiring the minimum human intervention.</p>

<h4 id="proposed-solution">Proposed solution</h4>
<p>The four steps of our methodology:</p>
<ol>
  <li>
<code class="language-plaintext highlighter-rouge">Vehicle detection</code>. Vehicles in a single frame are located and classified using a single-stage deep convolutional network detector <a href="https://github.com/ultralytics/yolov5" target="_blank" rel="noopener noreferrer">YOLOv5</a>.</li>
  <li>
<code class="language-plaintext highlighter-rouge">Stabilisation and registration</code>. Hybrid solution for jitter-free video registration in <d-cite key="lemaire2021registering"></d-cite>.</li>
  <li>
<code class="language-plaintext highlighter-rouge">Association</code>. The detections between different frames, that are likely to come from the same vehicle, are identified to produce trajectories. Our association algorithm matches trajectories to detections in a frame-wise manner using Kalman filters and solving the linear assignment problem. This algorithm is based on the <a href="https://github.com/abewley/sort" target="_blank" rel="noopener noreferrer">SORT</a> algorithm <d-cite key="SORT"></d-cite><d-cite key="deepSORT"></d-cite>.</li>
  <li>
<code class="language-plaintext highlighter-rouge">Orthorectification</code>. The coordinates are transformed from the visual to the metric domain in order to be able to compute the speeds of the vehicles.</li>
</ol>

<h2 id="results">Results</h2>

<p>At each frame, all the information required to compute the traffic summaries is contained in the estimated trajectories: the class (car, truck or utility), position and the velocity of all the tracked vehicles.</p>

<p>Videos contain the complete spatial information of the scene, which facilitates to estimate the occupancy and the mean spatial speed of the vehicles within certain region. We implement <code class="language-plaintext highlighter-rouge">zone detectors</code> for this purpose. Also, we implement <code class="language-plaintext highlighter-rouge">virtual loop detectors</code>, which allow us to estimate the number of vehicles passing through an edge, and to obtain the flow.</p>

<div class="row l-body-outset">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/station_air_1-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/station_air_1-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/station_air_1-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/station_air_1.png" title="example image">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Tracker interface. The zone detector (Z01) is highlighted in blue, the entries (E01, E02 and E03) and the exits (S01 and S02) are shown in green and yellow. The summaries (instantaneous count and speed in zone Z01 and cumulative counts in the entries and exits) are shown in the top right corner of the video.
</div>

<p><code class="language-plaintext highlighter-rouge">Even though the tracker often losses the trajectories of the vehicles (due to occlusions and noisy images), traffic metrics can be estimated without loosing much information</code>. For example, in the case of the time-space diagram, it suffices to know the start position and the travelled distance of each trajectory within the zone.</p>

<div class="row l-body-outset">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/station_air_2-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/station_air_2-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/station_air_2-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/station_air_2.png" title="example image">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Time-space diagram of the trajectories in the zone. The trajectories, in visual coordinates, for the period of time between minutes 22 and 28 are shown in the bottom panel. Note that even though the trajectories have discontinuities, it is still possible to observe the evolution of traffic and to detect traffic situations. For example, in the highlighted area between minutes 22 and 28, we can observe the formation of congestion and the shockwave propagating upstream caused by queuing vehicles trying to turn in the roundabout.
</div>

<p><code class="language-plaintext highlighter-rouge">Time series</code> of occupancy, mean spatial speed and flow could be useful in real-time traffic monitoring, since the trends can be observed easily and disaggregated by vehicle class. Moreover, the relation between these variables can be studied in the <code class="language-plaintext highlighter-rouge">traffic flow fundamental diagram</code>.</p>

<div class="row l-body-outset">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/station_air_3-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/station_air_3-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/station_air_3-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/station_air_3.png" title="example image">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Occupancy, mean spatial speed and flow. The time series (left panel) and fundamental diagram (right panel). The green rectangle highlights the period between minute 22 and minute 28, the same situation described in the time-space diagram above. 
</div>

<h3 id="performance">Performance</h3>

<p><code class="language-plaintext highlighter-rouge">How does the quality of the tracker impacts the quality of the traffic indicators?</code></p>

<p>We execute the tracker over a test video sequence using combinations of parameters with high, medium and bad performance (HOTA metric). This will allow us to measure the sensitivity of the flow, occupancy and speed estimators with respect to the quality of the tracker. Additionally, we compute the traffic indicators for <em>idealised</em> trajectories, obtained by executing the association step directly over the annotated data. In other words, the idealised trajectories can be defined as the result of tracking with perfect detections.</p>

<div class="row l-body-outset">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    <source media="(max-width: 480px)" srcset="/assets/img/station_air_4-480.webp"></source>
    <source media="(max-width: 800px)" srcset="/assets/img/station_air_4-800.webp"></source>
    <source media="(max-width: 1400px)" srcset="/assets/img/station_air_4-1400.webp"></source>
    <!-- Fallback to the original file -->
    <img class="img-fluid rounded z-depth-1" src="/assets/img/station_air_4.png" title="example image">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Sensitivity of traffic indicators to the choice of parameters of the Kalman filter. The traffic indicators computed with the three sets of parameters follow the same trend of the indicators produced with the idealised trajectories, but have a larger variation. The better the quality of the tracker, the better the traffic indicators computed from the trajectories.
</div>

<h2 id="conclusions">Conclusions</h2>

<p>We have shown how traffic indicators can be obtained from long videos captured by tethered UAVs. From the moment the raw video is captured to the calculation of traffic metrics, there are several aspects that need to be considered, such as video stabilisation and perspective. Our methodology addresses these aspects. Additionally, we show that <code class="language-plaintext highlighter-rouge">even when the tracker is not optimal, the produced traffic indicators are still reliable, and they can provide useful information</code>, such as the flow, occupancy and speeds of the vehicles within a zone.</p>

      </d-article>

      <d-appendix>
        <d-footnote-list></d-footnote-list>
        <d-citation-list></d-citation-list>
      </d-appendix>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        춸 Copyright 2022 Humberto  Gonz치lez Ram칤rez. Powered by <a href="http://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>.
Last updated: February 08, 2022.
      </div>
    </footer>

  </body>

  <d-bibliography src="/assets/bibliography/stationair.bib">
  </d-bibliography>

  <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

  <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

  <script src="/assets/js/distillpub/overrides.js"></script>

</html>
